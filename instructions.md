Full-Stack Engineering Assignment
Objective
Develop a No-Code/Low-Code web application that enables users to visually create and interact with intelligent workflows. The application should allow users to configure a flow of components that handle user input, extract knowledge from documents, interact with language models, and return answers through a chat interface.
Once a user builds a valid workflow, they should be able to ask questions. The system should process the query using the defined components and return a final response.
Tech Stack Requirements
â— Frontend: React.js
â— Backend: FastAPI
â— Database: PostgreSQL
â— Drag & Drop Library: React Flow
â— Vector Store: ChromaDB (or similar)
â— Embedding Model: OpenAI Embeddings
â— LLM: OpenAI GPT , Gemini
â— Web Search Tool: SerpAPI | Brave
â— Text Extraction: PyMuPDF or similar
Core Components
The application must allow users to build workflows using the following four components:
1. User Query Component
â— Accepts user queries via a simple interface.
â— Serves as the entry point for the workflow.
â— Sends the query forward to the next connected component.
2. KnowledgeBase Component
â— Allows uploading and processing of documents (e.g., PDFs).
â— Extracts text from files (using PyMuPDF or similar).
â— Generates embeddings from the text using OpenAI Embeddings , gemini embedding models etc.
â— Stores embeddings in a vector store (e.g., ChromaDB).
â— Retrieves relevant context based on the user query.
â— Context passing to the LLM Engine is optional.
3. LLM Engine Component
â— Accepts:
â—‹ Query from the User Query Component
â—‹ Optional context from the KnowledgeBase Component
â—‹ Optional custom prompt
â— Sends request to an LLM (e.g., OpenAI GPT , Gemini) to generate a response.
â— Optionally uses SerpAPI to retrieve information from the web.
â— Outputs a response and sends it to the Output Component.
4. Output Component
â— Displays the final response to the user.
â— Should function as a chat interface.
â— Follow-up questions should re-run the workflow using the same logic.
Workflow Execution
Build Stack
â— Users connect components in a logical order to define the workflow.
â— The application validates the workflow for correctness and configuration.
Chat with Stack
â— Users can enter queries in a chat interface.
â— Each query is passed through the workflow: User Query â†’ (Optional) KnowledgeBase â†’ LLM Engine â†’ Output
â— The final response is shown in the chat.
Frontend Specification
Component Library Panel
â— Lists all four available components.
â— Components can be dragged onto the canvas.
Workspace Panel
â— Visual canvas for building workflows using React Flow.
â— Should support:
â—‹ Drag-and-drop
â—‹ Connection lines with arrows
â—‹ Zoom and pan
â—‹ (Optional) Snap-to-grid for better alignment
Component Configuration Panel
â— Dynamically shows configuration options based on the selected component.
â— Should support appropriate inputs (text fields, dropdowns, toggles).
â— Optional: Tooltips or help for complex options
â— Optional: Import predefined configurations
Execution Controls
â— Build Stack: Validates and prepares the workflow for execution.
â— Chat with Stack: Opens the chat modal for query interaction.
â— Optional: Real-time logs or progress indicators for workflow execution
Deployment Specification:
â— Containerization: Dockerize the frontend, backend, and any other microservice. Provide Dockerfiles and instructions for building images.
â— Kubernetes Deployment(Optional): Create Kubernetes manifests or Helm charts for deploying the application components on a Kubernetes cluster. Include instructions for setting up the deployment on a local Kubernetes cluster (e.g., minikube) or a cloud-based Kubernetes service (e.g., AWS EKS, Google GKE).
Monitoring (Optional):
â— Monitoring: Set up Prometheus for collecting metrics and Grafana for dashboard visualization. Include Kubernetes manifests or configuration for deploying these tools alongside the application. Ensure that key metrics from the application, database, and any middleware are being monitored.
â— Logging: Configure the application to emit logs in a structured format. Set up the ELK Stack for log aggregation and visualization. Include setup instructions or configuration as part of the deployment process
Figma Design
Use the following Figma design as reference: ğŸ”— Figma Design URL
Backend Specification
â— Use FastAPI to expose endpoints for:
â—‹ Uploading and processing documents
â—‹ Storing and retrieving embeddings
â—‹ Running the workflow based on connections
â—‹ LLM and SerpAPI interaction
â— Orchestrate the component logic in the order defined by the userâ€™s workflow
Database Specification
â— Use PostgreSQL to:
â—‹ Store document metadata
â—‹ Store workflow definitions (optional)
â—‹ Store chat logs (optional)
Assignment Deliverables
â— âœ… Full source code (frontend + backend)
â— âœ… README with setup and run instructions
â— âœ… Clear component structure and modular design
â— âœ… Video demo or screen recording (optional but preferred)
â— âœ… (Optional) Architecture diagram or simple flowchart
Evaluation Criteria
â— Functional correctness and adherence to requirements
â— UI/UX quality and usability of the workflow builder
â— Backend architecture and API design
â— Code clarity, organization, and documentation
â— Correct use of tools (LLM, embeddings, vector DB, web search)
â— Extensibility and modularity
Optional Features
â— Workflow saving/loading from the database
â— Chat history persistence
â— Execution logs
â— User authentication